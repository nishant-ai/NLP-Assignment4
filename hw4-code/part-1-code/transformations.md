# Data Transformations for Q2

## Assignment Requirement
Design a transformation of the test dataset to serve as out-of-distribution (OOD) evaluation. The transformation should:
- Be "reasonable" (could occur in real user input)
- Preserve the original label (humans would assign same sentiment)
- Not be trivial (should cause model performance to drop)

## Possible Transformations Considered

### 1. Synonym Replacement
**Description:** Randomly replace 15-20% of words with synonyms from WordNet.

**Process:**
- Tokenize sentence into words
- For each word, with probability p=0.15-0.20:
  - Query WordNet for synsets
  - Select random synonym from available lemmas
  - Replace original word with synonym
- Skip proper nouns and words without synonyms

**Example:**
- Original: "The movie was excellent and entertaining"
- Transformed: "The film was outstanding and amusing"

**Why reasonable:** People naturally use different words to express the same meaning. Paraphrasing is common in reviews.

**Expected impact:** 3-5% accuracy drop (might need combining with other methods)

---

### 2. Character-Level Typos
**Description:** Introduce realistic typing errors to 10-15% of words.

**Process:**
- Select words randomly (only words with length > 3)
- Apply one of the following typo types:
  - **Adjacent character swap:** "great" → "graet"
  - **Character deletion:** "movie" → "moie"
  - **Character duplication:** "good" → "goood"
  - **Neighboring key replacement:** "like" → "loke" (i→o on QWERTY)

**Example:**
- Original: "This movie was absolutely terrible"
- Transformed: "This moive was absolutley terribel"

**Why reasonable:** Typos are extremely common in user-generated content, especially on mobile devices. Text remains understandable.

**Expected impact:** 4-7% accuracy drop

---

### 3. Contraction/Expansion
**Description:** Convert between contracted and expanded forms.

**Process:**
- "don't" ↔ "do not"
- "can't" ↔ "cannot"
- "I'm" ↔ "I am"

**Example:**
- Original: "I don't think this movie is good"
- Transformed: "I do not think this movie is good"

**Why reasonable:** Users write with varying formality levels.

**Expected impact:** 1-3% accuracy drop (too weak - models handle this well)

---

### 4. Combined: Synonym + Typo
**Description:** Apply both synonym replacement and typos.

**Process:**
- 15% of words: synonym replacement
- 10% of words: introduce typos
- Maximum 25% total words modified

**Example:**
- Original: "The movie was excellent and very entertaining"
- Transformed: "The film was excelent and vrey amusing"

**Why reasonable:** Real users both paraphrase and make typing errors.

**Expected impact:** 6-10% accuracy drop

---

## Chosen Transformation

**Selected:** Character-Level Typos

**Rationale:**
1. **Simplicity:** Easier to implement reliably than synonym replacement
2. **Effectiveness:** Expected 4-7% drop meets the >4% requirement for full points
3. **Realism:** Highly realistic - typos are ubiquitous in online reviews
4. **Sentiment preservation:** Typos don't change meaning, only spelling
5. **Robustness:** Works consistently across different review lengths and styles

**Implementation Details:**
- Target: 15% of words in each review
- Only apply to words with length > 3 characters
- Typo distribution:
  - 40% character swaps (adjacent positions)
  - 30% character deletion
  - 30% character duplication
- Never modify first or last character of a word (maintains readability)

**Why not others:**
- Synonym replacement alone might not reach 4% drop threshold
- Combined approach is more complex and harder to debug
- Contractions are too weak (BERT handles them easily)

---

## Actual Examples from Implementation

Below are real examples generated by our transformation function during testing:

### Example 1: Positive Review (Label preserved)
**Original:**
> "When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story..."

**Transformed:**
> "When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong? Very quickly, however, I realized that this story was about A Thousand **Oter** Things besides just Acres. I started crying and couldn't stop **unttil** long after the movie ended. Thank you Jane, Laura and Jocelyn, for **briinging** us such a wonderfully subtle and compassionate **move**!"

**Changes:** Oter (Other), unttil (until), briinging (bringing), move (movie)

---

### Example 2: Positive Review (Label preserved)
**Original:**
> "This is the latest entry in the long series of films with the French agent..."

**Transformed:**
> "This is the latest **enntry** in the long series of films with the **Frnech** agent, O.S.S. 117 (the French **anwer** to James Bond). The series was launched in the **ealry** 1950's, and spawned at least **egiht** films..."

**Changes:** enntry (entry), Frnech (French), anwer (answer), ealry (early), egiht (eight)

---

### Example 3: Negative Review (Label preserved)
**Original:**
> "This movie was so frustrating. Everything seemed energetic and I was totally prepared to have a good time..."

**Transformed:**
> "This movie was so frustrating. Everything seemed energetic and I was totally prepared to have a good **tiime**. I at least thought I'd be able to **stnd** it. But, I was wrong. **Frist**, the **werd** looping? It was like **watchhing** 'America's Funniest Home Videos'."

**Changes:** tiime (time), stnd (stand), Frist (First), werd (weird), watchhing (watching)

---

### Example 4: Simple Test Case
**Original:**
> "This movie was absolutely fantastic and entertaining throughout."

**Transformed:**
> "This **mvie** was absolutely fantastic and entertaining throughout."

**Changes:** mvie (movie - deleted 'o')

---

## Expected Outcome

**Original test accuracy:** ~91%
**Transformed test accuracy:** ~85% (6% drop)
**Goal:** Demonstrate model's brittleness to minor input perturbations that don't affect human understanding

**Key Observations:**
- All examples remain easily readable by humans
- Sentiment is completely preserved (positive stays positive, negative stays negative)
- Typos are realistic and common in real user reviews
- Approximately 15% of words are modified per review
- Mix of swap, delete, and duplicate operations creates natural-looking errors

---

## Q3: Data Augmentation

### Approach

To improve model robustness on transformed (OOD) data, we apply **data augmentation**:
- Take the original training dataset (25,000 examples)
- Apply our typo transformation to 5,000 randomly selected training examples
- Combine original + transformed data for a total of 30,000 training examples
- Train a new model on this augmented dataset

### Implementation

The augmented training set consists of:
- **Original examples:** 25,000 (100% of training data)
- **Transformed examples:** 5,000 (20% additional augmented data)
- **Total:** 30,000 training examples

Augmentation process:
1. Load original training dataset
2. Randomly sample 5,000 examples
3. Apply `custom_transform()` to create typo-corrupted versions
4. Concatenate original + transformed examples
5. Create DataLoader with combined dataset

### Expected Results

#### Performance Predictions:

**Model trained on original data only:**
- Original test set: ~91%
- Transformed test set: ~85% (6% drop)

**Model trained on augmented data (original + typos):**
- Original test set: ~90-91% (minimal drop)
- Transformed test set: ~88-89% (3-4% improvement)

### Analysis

#### 1. Did data augmentation improve performance on transformed test data?

**Expected: YES**

By exposing the model to typo-corrupted examples during training, it learns to be robust to character-level perturbations. The model sees patterns like:
- "moive" → positive sentiment
- "terribel" → negative sentiment

This helps it generalize better to similar typos at test time.

#### 2. How did data augmentation affect performance on original test data?

**Expected: Minimal impact or slight decrease**

The model maintains similar performance on clean data because:
- 83% of training data (25k/30k) remains unchanged
- The model learns to handle both clean and noisy inputs
- Modern architectures like BERT are robust enough to not overfit to noise

Possible slight decrease (0-1%) because:
- Model capacity is now split between learning clean and noisy patterns
- Training signal is slightly diluted with augmented examples

#### 3. Intuitive Explanation

**Why augmentation works:**

Think of the model as learning to read handwriting. If you only train it on perfect handwriting, it struggles with messy writing. But if you show it both perfect AND messy examples during training, it learns that "mvie" and "movie" both refer to the same concept.

Data augmentation creates **invariance** to typos:
- The model learns that character-level noise doesn't affect sentiment
- It focuses on robust features (word patterns, context) rather than exact spelling
- It becomes less brittle to input perturbations

**Trade-off:**
- Gain: Robustness to distribution shift (typos)
- Cost: Slightly more complex decision boundary

#### 4. Limitation of This Data Augmentation Approach

**Key Limitation: Augmentation must match the distribution shift**

This approach only works when:
- You know what transformations to expect at test time
- The OOD data follows the same pattern as your augmentation

**Specific limitations:**

1. **Not generalizable to unknown OOD scenarios**
   - Our augmentation only helps with typos
   - Won't help with other shifts: slang, different domains, adversarial attacks
   - Example: If test data has synonym replacements instead of typos, augmentation won't help

2. **Requires domain knowledge**
   - We had to manually design the transformation
   - In real-world deployment, you don't know what OOD shifts will occur
   - Can't augment for every possible variation

3. **Computational cost**
   - Training on 30k examples instead of 25k (20% longer)
   - Need to generate and store augmented data
   - For large datasets, this becomes expensive

4. **Potential for overfitting to augmentation**
   - If augmentation is too aggressive or unrealistic, model learns wrong patterns
   - May hurt performance if augmentation doesn't match real OOD distribution
   - Example: If we augment with 80% typos, model might expect mostly typos

5. **Doesn't solve fundamental robustness problem**
   - Model still vulnerable to other types of perturbations
   - This is a band-aid, not a systematic solution
   - Better approach: architectures inherently robust to noise (e.g., character-level models)

**Alternative approaches to consider:**
- Character-aware models (less sensitive to typos by design)
- Adversarial training (more general robustness)
- Test-time adaptation (adapt to actual OOD distribution)
- Domain adaptation techniques

### Summary

Data augmentation is a practical technique that:
- ✓ Improves robustness to known distribution shifts
- ✓ Maintains performance on original distribution
- ✗ Requires knowing the shift in advance
- ✗ Doesn't generalize to unknown OOD scenarios
- ✗ Adds computational overhead

It's a useful tool but not a complete solution to the OOD generalization problem.
