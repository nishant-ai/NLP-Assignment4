# NLP HW4 Part-1: Experiment Summary

## Overview
This document summarizes what the automated script will do for Part-1 of the assignment.

## Experiments Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     START EXPERIMENTS                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q1: Train Original Model                                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ Load IMDB dataset (25k train, 25k test)                       â”‚
â”‚ â€¢ Train BERT-base-cased for 3 epochs                            â”‚
â”‚ â€¢ Evaluate on original test set                                 â”‚
â”‚ â€¢ Save model to ./out/                                          â”‚
â”‚                                                                  â”‚
â”‚ Command: python3 main.py --train --eval                         â”‚
â”‚ Output: out_original.txt                                        â”‚
â”‚ Expected Accuracy: >91%                                         â”‚
â”‚ Time: ~45 minutes                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q2: Evaluate on Transformed Data                                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ Load model from ./out/                                        â”‚
â”‚ â€¢ Transform test set (introduce typos)                          â”‚
â”‚ â€¢ Evaluate on transformed test set                              â”‚
â”‚                                                                  â”‚
â”‚ Command: python3 main.py --eval_transformed --model_dir ./out   â”‚
â”‚ Output: out_transformed.txt                                     â”‚
â”‚ Expected: 4-8% accuracy drop                                    â”‚
â”‚ Time: ~5 minutes                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q3: Train with Data Augmentation                                â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ Original training data: 25k examples                          â”‚
â”‚ â€¢ Sample 5k random examples and transform them                  â”‚
â”‚ â€¢ Combine: 25k original + 5k transformed = 30k total            â”‚
â”‚ â€¢ Train new BERT model for 3 epochs                             â”‚
â”‚ â€¢ Evaluate on transformed test set                              â”‚
â”‚ â€¢ Save model to ./out_augmented/                                â”‚
â”‚                                                                  â”‚
â”‚ Command: python3 main.py --train_augmented --eval_transformed   â”‚
â”‚ Output: out_augmented_transformed.txt                           â”‚
â”‚ Expected: Better than Q2 on transformed data                    â”‚
â”‚ Time: ~55 minutes                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q3 (continued): Evaluate Augmented Model on Original Data       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ Load augmented model from ./out_augmented/                    â”‚
â”‚ â€¢ Evaluate on original test set                                 â”‚
â”‚ â€¢ Compare with Q1 results                                       â”‚
â”‚                                                                  â”‚
â”‚ Command: python3 main.py --eval --model_dir out_augmented       â”‚
â”‚ Output: out_augmented_original.txt                              â”‚
â”‚ Expected: Slightly lower than Q1                                â”‚
â”‚ Time: ~5 minutes                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Results Summary                                         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ â€¢ Extract accuracy from all experiments                         â”‚
â”‚ â€¢ Calculate performance changes                                 â”‚
â”‚ â€¢ Generate analysis report                                      â”‚
â”‚ â€¢ Create submission package                                     â”‚
â”‚                                                                  â”‚
â”‚ Output: results_summary.txt                                     â”‚
â”‚ Time: <1 minute                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXPERIMENTS COMPLETE                          â”‚
â”‚                                                                  â”‚
â”‚ Total Time: ~2 hours                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## What Gets Logged

### 1. Main Log (`main_log.txt`)
- Timestamp for each experiment start/end
- Success/failure status
- Extracted accuracy scores
- File operations (copies, moves)

### 2. Experiment Logs (individual `.log` files)
- Full command output
- Training progress bars
- Model loading/saving messages
- Evaluation metrics
- Any errors or warnings

### 3. Results Summary (`results_summary.txt`)
- All accuracy scores in one place
- Performance comparisons:
  - Original vs Transformed
  - Before vs After Augmentation
  - Original Model vs Augmented Model

## File Organization

```
hw4-code/part-1-code/
â”‚
â”œâ”€â”€ main.py                              # Your code
â”œâ”€â”€ utils.py                             # Your transformation
â”‚
â”œâ”€â”€ run_all_experiments.py               # Main runner (Python)
â”œâ”€â”€ run_all_experiments.sh               # Main runner (Bash)
â”œâ”€â”€ submit_job_slurm.sh                  # SLURM submission script
â”‚
â”œâ”€â”€ out/                                 # Q1 model checkpoint
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ out_augmented/                       # Q3 model checkpoint
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ submission_package_YYYYMMDD_HHMMSS/  # Ready for Gradescope
â”‚   â”œâ”€â”€ README.txt
â”‚   â”œâ”€â”€ results_summary.txt
â”‚   â”œâ”€â”€ out_original.txt                 # Q1
â”‚   â”œâ”€â”€ out_transformed.txt              # Q2
â”‚   â”œâ”€â”€ out_augmented_original.txt       # Q3
â”‚   â””â”€â”€ out_augmented_transformed.txt    # Q3
â”‚
â”œâ”€â”€ logs_YYYYMMDD_HHMMSS/                # All logs
â”‚   â”œâ”€â”€ main_log.txt                     # Master log
â”‚   â”œâ”€â”€ q1_train_eval_original.log       # Q1 output
â”‚   â”œâ”€â”€ q2_eval_transformed.log          # Q2 output
â”‚   â”œâ”€â”€ q3_train_augmented.log           # Q3 training
â”‚   â”œâ”€â”€ q3_eval_augmented_original.log   # Q3 eval
â”‚   â””â”€â”€ results_summary.txt              # Summary
â”‚
â””â”€â”€ outputs_YYYYMMDD_HHMMSS/             # Intermediate outputs
    â”œâ”€â”€ q1_out_original.txt
    â”œâ”€â”€ q2_out_transformed.txt
    â”œâ”€â”€ q3_out_augmented_original.txt
    â””â”€â”€ q3_out_augmented_transformed.txt
```

## Expected Results

### Q1: Baseline Performance
```
Original Model on Original Test Set
  Accuracy: 0.92XX (92.XX%)
```
**Required**: >91% for full points

### Q2: Robustness Test
```
Original Model on Transformed Test Set
  Accuracy: 0.86XX (86.XX%)

Accuracy drop: 5-6 percentage points
```
**Required**: >4% drop for full points (15/15)

### Q3: Data Augmentation Effect
```
Augmented Model on Transformed Test Set
  Accuracy: 0.88XX (88.XX%)
  Improvement: +2-3 percentage points over Q2

Augmented Model on Original Test Set
  Accuracy: 0.91XX (91.XX%)
  Change: -0.5 to -1.5 percentage points vs Q1
```

## Analysis Questions (for writeup)

The results will help you answer:

1. **Q2**: How much does the transformation degrade performance?
   - Check difference between Q1 and Q2 accuracies

2. **Q3**: Does data augmentation help on transformed data?
   - Compare Q2 vs Q3 on transformed test set

3. **Q3**: What's the trade-off on original data?
   - Compare Q1 vs Q3 on original test set

4. **Q3**: Why does augmentation work/not work?
   - Model sees similar patterns during training
   - Trade-off between robustness and specialization

5. **Q3**: Limitation of this approach?
   - Only helps with seen transformations
   - Doesn't generalize to other OOD patterns
   - Requires knowing what transformations to expect

## Transformation Details

Your implemented transformation ([utils.py:37-86](utils.py#L37-L86)):
- **Type**: Character-level typos
- **Probability**: 15% of words
- **Methods**:
  - Swap adjacent characters
  - Delete a character
  - Duplicate a character
- **Target**: Words >3 characters

## Quick Commands

### Start experiments
```bash
python3 run_all_experiments.py
```

### Submit to SLURM
```bash
sbatch submit_job_slurm.sh
```

### Check progress
```bash
tail -f logs_*/main_log.txt
```

### View results
```bash
cat logs_*/results_summary.txt
```

### Download results
```bash
tar -czf submission.tar.gz submission_package_*/
scp user@hpc:~/path/submission.tar.gz .
```

## Troubleshooting

### Low Q1 Accuracy (<91%)
- Check if training completed all epochs
- Verify GPU is being used
- Check for errors in training loop

### Small accuracy drop in Q2 (<4%)
- Transformation might be too weak
- Increase typo probability in utils.py
- Or make transformations more aggressive

### No improvement in Q3
- Check that augmented data was created correctly
- Verify 5k examples were added
- Check if transformation is same in train/test

### Out of memory
- Reduce batch size (default: 8 â†’ 4)
- Request more GPU memory
- Use smaller subset for debugging

## Next Steps After Completion

1. âœ… Check `experiment_completed.txt`
2. âœ… Review `results_summary.txt`
3. âœ… Download `submission_package_*/` folder
4. âœ… Upload 4 .txt files to Gradescope
5. âœ… Write analysis for Q3 using the results
6. âœ… Save model checkpoints for your records

Good luck! ğŸ“
